%\documentclass[sigconf, authordraft]{acmart}
\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage[underline=false]{pgf-umlsd}

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.1145/nnnnnnn.nnnnnnn}

% ISBN
\acmISBN{978-x-xxxx-xxxx-x/YY/MM}

% Conference
\acmConference[GECCO '19]{the Genetic and Evolutionary Computation Conference 2019}{July 13--17, 2019}{Prague, Czech Republic}
\acmYear{2019}
\copyrightyear{2019}

%\acmArticle{4}
\acmPrice{15.00}

% These commands are optional
%\acmBooktitle{Transactions of the ACM Woodstock conference}
%\editor{Jennifer B. Sartor}
%\editor{Theo D'Hondt}
%\editor{Wolfgang De Meuter}


\begin{document}

<<setup, cache=FALSE,echo=FALSE>>=
library(reshape2)
library(ggplot2)
library(ggthemes)

data.freqs.threads <- read.csv('../data/gecco-2019-freqs-threads.csv')
data.compress.threads <- read.csv('../data/gecco-2019-compress-threads.csv')
data.freqs.generations <- read.csv('../data/gecco-2019-freqs-generations.csv')
data.compress.generations <- read.csv('../data/gecco-2019-compress-generations.csv')
data.evostar <- read.csv("../data/evostar2019.csv")

data.generations <- data.frame(
    strategy=c(rep("Compress",length(data.compress.generations$Generation.Gap)),
               rep("EDA",length(data.freqs.generations$Generation.Gap)),
               rep("Full",length(data.evostar$gap))),
    gap=c(data.compress.generations$Generation.Gap,data.freqs.generations$Generation.Gap,data.evostar$gap),
    evaluations=c(data.compress.generations$Evaluations,data.freqs.generations$Evaluations,data.evostar$evaluations),
    time=c(data.compress.generations$Time,data.freqs.generations$Time,data.evostar$time) )




@

\title{Exploring concurrent and stateless evolutionary algorithms}
\titlenote{Produces the permission block, and
  copyright information}
\subtitle{Subtitle}
\subtitlenote{The full version of the author's guide is available as
  \texttt{acmart.pdf} document}

  \author{Anonymous Author 1}
  \orcid{1234-5678-9012}
  \affiliation{%
    \institution{Anonymous institute 1}
    \streetaddress{P.O. Box 1212}
    \city{Dublin}
    \state{Ohio}
    \postcode{43017-6221}
  }
  \email{aa1@ai1.com}
  
  \author{Anonymous Author 2}
  \affiliation{%
    \institution{Anonymous institute 2}
    \streetaddress{P.O. Box 1212}
    \city{Dublin}
    \state{Ohio}
    \postcode{43017-6221}
  }
  \email{2aa@ai2.com}

  \author{Anonymous Author 3}
  \affiliation{%
    \institution{Anonymous institute 2}
    \streetaddress{P.O. Box 1212}
    \city{Dublin}
    \state{Ohio}
    \postcode{43017-6221}
  }
  \email{2aa@ai2.com}

  \author{Anonymous Author 4}
  \affiliation{%
    \institution{Anonymous institute 2}
    \streetaddress{P.O. Box 1212}
    \city{Dublin}
    \state{Ohio}
    \postcode{43017-6221}
  }
  \email{2aa@ai2.com}
  
  % The default list of authors is too long for headers.
  \renewcommand{\shortauthors}{A. Author et al.}

  

\begin{abstract}
Concurrent algorithms use channels for communication, which implies
that communication is an integral part of them, so some attention must
be devoted to its design. In the design of concurrent evolutionary
algorithms, there are several options that can be used for performing
this communication. In this paper we will explore how  communication
overhead can be reduced, and how it influences scaling. The
evolutionary algorithm will use a concurrent language, and leverage
its capabilities. Eventually, we will try to prove how concurrent
version of algorithms offer a good option to leverage the
multi-threaded and multi-core capabilities of modern computers.

\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}


\keywords{ACM proceedings, \LaTeX, text tagging}


\maketitle

\section{Introduction}


Despite the emphasis on hardware-based techniques such as
cloud computing or GPGPU, there are not many papers \cite{Xia2010} dealing with
creating concurrent evolutionary algorithms that work in a single
computing node or that extend seamlessly from single to many computers.

The concurrent programming paradigm (or concurrency oriented
programming \cite{Armstrong2003}) is characterized by the presence of
programming constructs for managing processes like first-class
objects. That is, with native operators for acting upon them and the
possibility of using them as parameters or as return values of 
a function. 
The latter yields to changes in the implementation of concurrent algorithms due to the
direct mapping between patterns of communications and processes with
language expressions; on one hand it becomes simpler since the
language provides an abstraction for communication, on the other hand
it changes the paradigm for implementing algorithms, since these new
communication constructs have to be taken into account. 

Moreover, concurrent programming adds a layer of abstraction over the parallel
facilities of processors and operating systems, offering a
high-level interface that allows the user to program modules of code to
be executed in parallel threads \cite{andrews1991concurrent}.

Different languages offer different concurrency strategies depending on how they deal with shared state,
that is, data structures that could be accessed from several
processes. In this regard, there are two major fields (with some other
variations): 
\begin{itemize}
\item Actor-based concurrency \cite{schippers2009towards}
totally eliminates shared state by introducing a series of data
structures called {\em actors} that
store state and can mutate it locally. 
\item Process calculi or process algebra is a framework to describe
  systems that work with independent
  processes that interact between them using channels. One of the best
  known is called the {\em communicating sequential processes} (CSP)
methodology \cite{Hoare:1978:CSP:359576.359585}, which is effectively
stateless, with different processes reacting to a channel input without
changing state, and writing to these channels. Unlike actor based
concurrency, which keeps state local, in this case per-process state is totally
eliminated, with all computation state managed as messages in a channel.
\item Other, less well known models using, for instance, tuple
  spaces \cite{gelernter1985generative}.
\end{itemize}

Most modern languages, however, follow the CSP abstraction, and it has
become popular since it fits well other programming paradigms, like
reactive and functional programming, and allows for a more efficient
implementation, with less overhead, and with well-defined
primitives. This is why we will use it in this paper for creating new
evolutionary algorithms that live {\em natively} in these environments
and can thus be implemented easily in this kind of languages. We have chosen Perl 6, although 
other languages such as Go, are feasible alternatives.

In previous papers
\cite{Merelo:2018:MEA:3205651.3208317:anon,merelo:WEA:anon,} we
designed an evolutionary algorithm that fits well this architecture
and explored its possibilities. That initial exploration showed that
a critical factor within this algorithic model is communication between threads; therefore designing
efficient messages is high-priority to obtain a good algorithmic
performance and scaling. In this paper, we will test several
communication strategoes: a lossless one that compresses the population,
and a lossy one that sends a representation of population gene-wise
statistics.

\section{State of the Art}


This design has to take into account the communication/synchronization
between processes, which nowadays will be mainly threads. One of the best efforts to formalize
and simplify that is the Hoareâ€™s {\em Communicating Sequential
  Processes} \cite{Hoare:1978:CSP:359576.359585}, this interaction
description language is the theoretical support for many libraries and
new programming languages. This kind of concurrent programs is based
on {\em channels}, which are used to interchange message between the
different processes or threads; messages can be interchanged
asynchronously or synchronously. The Go language uses this kind of
model, and Perl 6 will use, among others (like {\em promises} or
low-level access to the creation of threads), this one.
Another, different, approach is actor-based
concurrency, \cite{schippers2009towards}. This actor model bans shared
state, with different {\em actors} communicating through messages \cite{erb2012concurrent}. 


The fact that messages have to be processed without secondary effects
and that actors do not share any kind of state makes concurrent
programming specially fit for functional languages or languages with
functional features; this has made this paradigm specially popular for
late cloud computing implementations; however, its presence in the EA
world is not so widespread, although some efforts have lately revived
the interest for this kind of paradigm \cite{swan2015research}. Several years ago was used in Genetic Programming
\cite{Briggs:2008:FGP:1375341.1375345,Huelsbergen:1996:TSE:1595536.1595579,walsh:1999:AFSFESIHLP}
and recently in neuroevolution \cite{Sher2013} but in EA its presence,
despite being scarce in the previous years
\cite{Hawkins:2001:GFG:872017.872197}, has experimented a certain rise
lately with papers such as \cite{valkov2018synthesis} which perform
program synthesis using functional programming or
\cite{barwell2017using} which uses the functional and parallel
language Erlang for an evolutionary multi-agent system.

Among languages with functional features, the languages Erlang and Scala have
embraced the actor model of concurrency and get excellent results in
many application domains; Clojure is another one with concurrent
features such as promises/futures, Software Transaction Memory and
agents; Kotlin \cite{simson2017open} has been recently used for
implementing a functional evolutionary algorithm framework.  

On the
other hand, Perl 6 \cite{Tang:2007:PRI:1190215.1190218} uses different
concurrency models, that go from implicit concurrency using a
particular function that automatically parallelizes operations on
iterable data structures, to explicit concurrency using threads. These
both types of concurrency will be analyzed in this paper, which uses
the {\tt Algorithm::Evolutionary::Simple} library for that language
which was presented in the same conference \cite{DBLP:conf/gecco/GuervosV18}

For instance, the EvAg model \cite{evag:gpem} is a locally concurrent and globally
parallel evolutionary algorithm that leaves the management of the
different agents (i.e. threads) to the underlying platform scheduler
and displays an interesting feature: the model is able to scale
seamlessly and take full advantage of CPU threads. In a first attempt
to measure the scalability of the approach experiments were conducted
in \cite{wcci:evoag} for a single and a dual-core processor showing
that, for cost functions passing some milliseconds of computing
time, the model was able to achieve near linear speed-ups . This study
was later on extended in \cite{DBLP:conf/evoW/LaredoBMG12} by scaling
up the experimentation to up to 188 parallel machines. The
reported speed-up was $\times 960$ which is beyond the linear $\times
188$ that could be expected if local concurrency were not taken into
account.  

The aforementioned algorithm used a protocol that worked
asynchronously, leveraging its peer-to-peer capabilities; in general
the design of concurrent EAs has to take into account the
communication/synchronization 
between processes, which nowadays will be mainly threads. Although the
paper above was original in its approach, other authors targeted
explicitly multi-core architectures, such as Tagawa
\cite{Tagawa201212} which used shared memory and a clever mechanism to
avoid deadlock. Other authors \cite{kerdprasop2012concurrent} actually
use a message-based architecture based in the concurrent functional
language Erlang, which separates GA populations as different
processes, although all communication takes place with a common
central thread. 

In our previous papers 
\cite{Merelo:2018:MEA:3205651.3208317:anon,Garcia-Valdez:2018:MEA:3205651.3205719:anon},
we presented the proof of concept and initial results with this kind
of stateless evolutionary algorithms, implemented in the Perl 6
language. These evolutionary algorithms use a single channel where
whole populations are sent. The (stateless) functions read a single
population from the channel, run an evolutionary algorithm for a fixed
number of generations, which we call the {\em generation gap} or
simply {\em gap}, and send the population in the final generation back
to the channel. Several populations are created initially, and a
concurrent {\em mixer} is run which takes populations in couples,
mixes them leaving only a single population with the best individuals
selected from the two merged populations.
 This {\em
  gap} is then conceptually, if not functionally, similar to the {\em
  time to migration} in parallel evolutionary algorithms (with which
concurrent evolutionary algorithms have a big resemblance).

We did some initial exploration of the parameter space in
\cite{merelo:WEA:anon}. In these initial explorations we realized
that the parameters we used had an influence at the algorithmic level,
but also at the implementation level, changing the wallclock
performance of the algorithm.

In this paper we will explore the parameter space systematically
looking particularly at two parameters that have a very important
influence on performance: population size and generation gap. Our
intention is to create a rule of thumb for setting them in this kind
of algorithms, so that they are able to achieve the best
performance. 

We will present the experimental setup next.

\section{Experimental setup}
\label{sec:exp}

\begin{figure}[h!tb]
  \centering
\includegraphics[width=0.95\columnwidth]{../figure/popmixer}
\caption{General scheme of operation of channels and thread groups. }
\label{fig:scheme}
\end{figure}
%

\begin{figure}[h!tb]
  \centering
  
\begin{sequencediagram}

\newthread[red]{E}{Evolver} 

\tikzstyle{inststyle}+=[rounded corners=3mm] 
\newinst{C}{Channel}

\tikzstyle{inststyle}+=[rounded corners=0]
\newthread[blue]{M}{Mixer}

\begin{call}{E}{evolve()}{E}{}\end{call}

\setthreadbias{east}
\begin{messcall}{E}{$pop_1$}{C} 
\mess{C}{$pop_1$}{M}
\end{messcall}

\prelevel\prelevel
\begin{call}{E}{evolve()}{E}{}\end{call}

\setthreadbias{east}
\begin{messcall}{E}{$pop_2$}{C}  
\mess{C}{$pop_2$}{M}
\end{messcall}

\prelevel\prelevel
\begin{call}{M}{mix()}{M}{}\end{call}

\postlevel\postlevel
\setthreadbias{west}
\begin{messcall}{M}{\shortstack{ \{\ $mixpop_1$,\\ $mixpop_2$,\\ \vdots \\ $mixpop_k$ \} }}{C}

\mess{C}{$mixpop_1$}{E} 
\begin{call}{E}{evolve()}{E}{}\end{call}

\setthreadbias{east}
\begin{messcall}{E}{$pop_3$}{C} 
\postlevel
\mess{C}{$mixpop_2$}{E} 
%\prelevel
\mess{C}{$pop_3$}{M}
\end{messcall}

\prelevel\prelevel
\begin{call}{E}{evolve()}{E}{}\end{call}

\setthreadbias{east}
\begin{messcall}{E}{$pop_4$}{C}
\mess{C}{$pop_4$}{M}
\end{messcall}

\setthreadbias{west}
\prelevel
\mess{C}{$mixpop_k$}{E}%\end{messcall}

\end{messcall}

\prelevel\prelevel
\begin{call}{M}{mix()}{M}{\vdots}\end{call}
\prelevel
\begin{call}{E}{evolve()}{E}{\vdots}\end{call}

\end{sequencediagram}

\caption{Schematic of communication between threads and channels for concurrent EAs.}
\label{fig:schematic}
\end{figure}


The setup is similar to the one used in previous experiments
\cite{Merelo:2018:MEA:3205651.3208317:anon}. Our intention was to
create a system that was not functionally equivalent to a sequential
evolutionary algorithms, and that followed the principle of
communicating sequential processes. In this kind of methodology, we
will have processes (or threads) communicating state through
channels. Every process itself will be stateless, reacting to the
presence of messages in the channels it is listening to and sending
result back to them, without changing state.

As in the previous papers, \cite{merelo:WEA:anon}, we will use two
groups of threads and two channels. We will see them in turns.

The two groups of threads perform the following
functions:\begin{itemize}
\item The {\em evolutionary} threads will be the ones that will be in
  principle running the evolutionary algorithm.
\item The {\em mixing} threads will {\em mix} populations, and create
  new ones as a mixture of them.
\end{itemize}

The two channels carry messages that are equivalent to populations,
but they do so in a different way:\begin{itemize}
  
\item The {\em evolutionary} channel will be used for carrying
  non-evolved, or generated, populations.
\item The {\em mixer} channel will carry, {\em in pairs}, evolved
  populations. 
\end{itemize}

These will be connected as shown in Figure \ref{fig:scheme}. The
evolutionary group of threads will read only from the evolutionary channel,
evolve for a number of generations, and place result in the mixer
channel; the mixer group of threads will read only from the mixer
channel, in pairs. From every pair, a random element is put back into
the mixer channel, and a new population is generated and sent back to
the evolutionary channel. The main objective of using two channels is
to avoid deadlocks; the fact that one population is written always
back to the mixer channel avoids starvation in the channel.



What we want to find out in these set of experiments is what is the
generation gap that gives the best performance in terms of raw time to
find a solution, as well as the best number of evaluations per
second. In order to do that, we prepared an experiment using the
OneMax function with 64 bits, a concurrent evolutionary algorithm such
as the one described in \cite{Merelo:2018:MEA:3205651.3208317:anon},
which is based in the free Perl 6 evolutionary algorithm library {\tt
  Algorithm::Evolutionary::Simple}, and run the experiments in a
machine with Ubuntu 18.04, an AMD Ryzen 7 2700X Eight-Core Processor
at 2195MHz. The Rakudo version was 6.d, which had recently been
released with many improvements to the concurrent core of the
language. All scripts, as well as processing scripts and data obtained
in the experiments are available, under a free license, from our GitHub
repository.

%
%  Figure with Plots goes here
%

We used a population size of 256, as well as generation gaps
increasing from 8 to 64. Many experiments were run for every
configuration, up to 150 in some cases. We logged the upper bound of
the number of evaluations needed (by multiplying the number of
messages by the number of generations and number of individuals
evaluated; this means that this number will be an upper bound, and not
the exact number of evaluations until a solution is reached). We will
first look at the general picture by plotting the wallclock time in seconds
(measured by taking the time of the starting of the algorithm and the
last message and subtracting the latter from the former) vs the
number of evaluations that have been performed. The result is shown in
Figure \ref{fig:evals}. Experiments with different generation gaps are
shown with different colors (where available) and shapes, and they
spread in an angle which is roughly bracketed by the experiments with
a generation gap of 8, which need the most time for the same number of
evaluations, and the experiments with a gap of 16, which usually need
the least. The experiments with gaps = 32 or 64 are somewhere in
between.

In that same chart it can also be observed that the number of
evaluations needed to find the 64 bit OneMax solution is quite
different. We make a boxplot of the number of evaluations vs the
generation gap in Figure \ref{fig:evals:bp}. This figure shows an
increasing number of evaluations per gap size. Differences are
significant between every generation gap and the next. This
increasing number of evaluations per generation gap is probably due to
the fact that the increasing number of isolated generations makes the
population lose diversity, making finding the solution increasingly
difficult. This is the same effect observed in parallel algorithms, as
reported in \cite{Cantu-Paz:1999:MPT:2933923.2934003}, so it is not
unexpected. What is unexpected is the combination of generation gap
size and the concurrent algorithm, since it is impossible to know in
advance what is the optimal computation to communication balance.
% Here it would be interesting to describe why is unexpected? - Juanlu
% done - JJ

We plot the number of evaluations per second in Figure
\ref{fig:evals:avg}. These show a big difference for a generation gap
of 16, with a number of evaluations which is almost 50\% higher than
for the rest of the generation gaps, where the difference is not so
high. 


The number of evaluation per second does not follow a clear trend. It
falls and remains flat for a generation gap higher than 16; it is also slightly higher than for the minimum
generation gap that has been evaluated, 8. This generation gap,
however, presents also the lowest number of evaluations to solution,
which means that, on average, the solution will be found faster with a
generation gap of 8 or 16. This is shown in Figure \ref{fig:time}.
% I don't feel confortable modifying this paragraph, but I find it a bit twisted - Juanlu
% Rewritten - JJ


\begin{figure*}[h!tb]
  \centering
\includegraphics[width=0.95\textwidth]{../figure/screenshot}
\caption{Screenshot using the htop utility of the used machine running
  two experiments at the same time. As it can be seen, all processors
  are kept busy, with a very high load average. }
\label{fig:screenshot}
\end{figure*}
%


\section{Conclusions}
\label{sec:conclusions}
In this paper we have set out to explore the interaction between the
generation gap and the algorithmic parameters in a concurrent and stateless evolutionary algorithm. From the point of view
of the algorithm, increasing the generation gap favors exploitation
over exploration, which might be a plus in some problems, but also
decreases diversity, which might lead to premature convergence; in a
parallel setting, this will make the algorithm need more evaluations
to find a solution. The effect in a concurrent program goes in the
opposite direction: by decreasing communication, the amount of
code that can be executed concurrently increases, increasing
performance. Since the two effects cancel out, in this paper we have
used a experimental methodology to find out what is the combination
that is able to minimize wallclock time, which is eventually what we
are interested in by maximizing the number of evaluations per second
while, at the same time, increasing by a small quantity the number of
evaluations needed to find the solution.

For the specific problem we have used in this short paper, a 64-bit
onemax, the generation gap that is in that area is 16. The time to
communication for that specific generation gap is around 2 seconds,
since 16 generations imply 4096 evaluations and evaluation speed is
approximately 2K/s. This gives us a ballpark of the amount of
computation that is needed for concurrency to be efficient. In this
case, we are sending the whole population to the communication
channel, and this implies a certain overhead in reading, transmiting
and writing. Increasing the population size also increases that
overhead.

We can thus deduce than the amount of computation, for this particular
machine, should be on the order of 2 seconds, so that it effectively
overcomes the amount of communication needed. This amount could be
played out in different way, for instance by increasing the
population; if the evaluation function takes more time, different
combinations should be tested so that no message is sent unless that
particular amount of time is reached.

With these conclusions in mind, we can set out to work with other
parameters, such as population size or number of initial populations,
so that the loss of diversity for bigger population sizes is
overcome. Also we have to somehow overcome the problem of the message
size by using a statistical distribution of the population, or simply
other different setup. This is left as future work.%\end{document}  % This is where a 'short' article might terminate



\begin{acks}
Acknowledgements taking\\
this much\\
space

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{../geneura,../concurrent,../perl6} 

\end{document}
